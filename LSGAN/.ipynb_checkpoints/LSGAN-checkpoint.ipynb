{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSGAN\n",
    "\n",
    "## DCGAN \n",
    "### 最初のGANからの変更点\n",
    "- 畳み込み層の導入\n",
    "- Batch Normalization\n",
    "- Leaky ReLU\n",
    "\n",
    "## LSGAN\n",
    "損失関数が二乗誤差損失\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr_D, betas=(beta1, beta2), weight_decay=1e-5)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr_G, betas=(beta1, beta2), weight_decay=1e-5)\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1)\n",
    "#fixed_noise = fixed_noise.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(G, D, dataloader, num_epochs):\n",
    "    \n",
    "    #==== save\n",
    "    d_loss_list = []\n",
    "    g_loss_list = []\n",
    "    \n",
    "    #==== device ====\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device : \", device)\n",
    "    \n",
    "    #==== optimizer setting ====\n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    \n",
    "    g_optimizer = optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
    "    \n",
    "    #Loss Function\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    \n",
    "    #parameter\n",
    "    z_dim = 20\n",
    "    mini_batch_size = 64\n",
    "    \n",
    "    #Network\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "    \n",
    "    G.train()\n",
    "    D.train()\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    \n",
    "    #iteration\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for images in dataloader:\n",
    "            \n",
    "            #==== Discriminator ====\n",
    "            if images.size()[0] == 1:\n",
    "                continue\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            mini_batch_size = images.size()[0]\n",
    "            label_real = torch.full((mini_batch_size, ), 1).to(device)\n",
    "            label_fake = torch.full((mini_batch_size, ), 0).to(device)\n",
    "            \n",
    "            d_out_real = D(images)\n",
    "            \n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            \n",
    "            fake_images = G(input_z)\n",
    "            \n",
    "            d_out_fake = D(fake_images)\n",
    "            \n",
    "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            #==== Generator ====\n",
    "            \n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            \n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake = D(fake_images)\n",
    "            \n",
    "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
    "            \n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += d_loss.item()\n",
    "            \n",
    "        d_loss_list.append(epoch_d_loss/batch_size)\n",
    "        g_loss_list.append(epoch_g_loss/batch_size)\n",
    "        \n",
    "        print(f\"#======Epoch: {epoch}=======\")\n",
    "        print(f'd_loss: {epoch_d_loss/batch_size}, g_loss: {epoch_g_loss/batch_size}')\n",
    "        \n",
    "    \n",
    "    return G, D, (d_loss_list, g_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
